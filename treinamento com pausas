import os
import torch
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import torch.nn as nn
import torch.optim as optim
import torchvision.models.segmentation as segmentation

# Caminhos para imagens e máscaras
images_dir = 'c:/Users/João Vitor/Downloads/imgs/'
masks_dir = 'c:/Users/João Vitor/Downloads/masks/'

# Definindo a transformação das imagens e máscaras
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

class SingleImageDataset(Dataset):
    def __init__(self, images_dir, masks_dir, transform=None):
        self.images_dir = images_dir
        self.masks_dir = masks_dir
        self.image_files = sorted(os.listdir(images_dir))
        self.mask_files = sorted(os.listdir(masks_dir))
        self.transform = transform

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = os.path.join(self.images_dir, self.image_files[idx])
        mask_path = os.path.join(self.masks_dir, self.mask_files[idx])
        
        image = Image.open(img_path).convert('RGB')
        mask = Image.open(mask_path).convert('L')  # L = modo de imagem em escala de cinza
        
        if self.transform:
            image = self.transform(image)
            mask = transforms.Resize((256, 256))(mask)  # Redimensionar máscara para o tamanho adequado
            mask = transforms.ToTensor()(mask)  # Convertendo para tensor
            mask = mask.squeeze(0).long()  # Remover o canal e converter para rótulos inteiros

        return image, mask

# Carregando o dataset
dataset = SingleImageDataset(images_dir, masks_dir, transform=transform)
batch_size = 2  # Ajuste conforme necessário
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Definindo o modelo DeepLabV3, função de perda e otimizador
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = segmentation.deeplabv3_resnet101(pretrained=False, num_classes=21)  # Ajuste num_classes conforme necessário
model.to(device)
criterion = nn.CrossEntropyLoss()  # DeepLabV3 normalmente usa CrossEntropyLoss
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Inicializando ReduceLROnPlateau
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)

def save_checkpoint(state, filename='checkpoint.pth.tar'):
    torch.save(state, filename)

def train_model(model, dataloader, criterion, optimizer, scheduler, device, num_epochs, start_epoch=0, early_stop_patience=5):
    model.train()
    best_loss = float('inf')
    epochs_no_improve = 0
    
    for epoch in range(start_epoch, num_epochs):
        epoch_loss = 0.0
        for images, masks in dataloader:
            images = images.to(device)
            masks = masks.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)['out']  # A saída do DeepLabV3 é um dicionário
            loss = criterion(outputs, masks)  # CrossEntropyLoss espera os rótulos como inteiros
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
        
        epoch_loss /= len(dataloader)
        scheduler.step(epoch_loss)
        
        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')
        
        # Checkpoint e Early Stopping
        if epoch_loss < best_loss:
            best_loss = epoch_loss
            epochs_no_improve = 0
            save_checkpoint({
                'epoch': epoch + 1,
                'state_dict': model.state_dict(),
                'optimizer': optimizer.state_dict(),
                'loss': epoch_loss,
            }, filename='best_model.pth.tar')
        else:
            epochs_no_improve += 1
            if epochs_no_improve >= early_stop_patience:
                print("Early stopping!")
                break

    return model

# Carregando o checkpoint, se disponível
checkpoint_path = 'best_model.pth.tar'
if os.path.exists(checkpoint_path):
    checkpoint = torch.load(checkpoint_path)
    model.load_state_dict(checkpoint['state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer'])
    start_epoch = checkpoint['epoch']
    print(f'Checkpoint carregado. Retomando do epoch {start_epoch}.')
else:
    start_epoch = 0

# Treinando o modelo
num_epochs = 5  # Ajuste conforme necessário
trained_model = train_model(model, dataloader, criterion, optimizer, scheduler, device, num_epochs, start_epoch=start_epoch)

# Salvando o modelo treinado
torch.save(trained_model.state_dict(), 'workspace jeivy/deeplabv3_model.pth')
