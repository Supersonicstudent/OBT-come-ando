import os
import torch
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import torch.nn as nn
import torch.optim as optim
import torchvision.models.segmentation as segmentation
from torch.optim.lr_scheduler import ReduceLROnPlateau

# Caminhos para imagens e máscaras
images_dir = 'c:/Users/João Vitor/Downloads/imgs/'
masks_dir = 'c:/Users/João Vitor/Downloads/masks/'

# Definindo a transformação das imagens e máscaras com Data Augmentation
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomHorizontalFlip(),  # Aumento de dados
    transforms.RandomRotation(10),      # Aumento de dados
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

class SingleImageDataset(Dataset):
    def __init__(self, images_dir, masks_dir, transform=None):
        self.images_dir = images_dir
        self.masks_dir = masks_dir
        self.image_files = sorted(os.listdir(images_dir))
        self.mask_files = sorted(os.listdir(masks_dir))
        self.transform = transform

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = os.path.join(self.images_dir, self.image_files[idx])
        mask_path = os.path.join(self.masks_dir, self.mask_files[idx])
        
        image = Image.open(img_path).convert('RGB')
        mask = Image.open(mask_path).convert('L')  # L = modo de imagem em escala de cinza
        
        if self.transform:
            image = self.transform(image)
            mask = transforms.Resize((256, 256))(mask)  # Redimensionar máscara para o tamanho adequado
            mask = transforms.ToTensor()(mask)  # Convertendo para tensor
            mask = mask.squeeze(0).long()  # Remover o canal e converter para rótulos inteiros

        return image, mask

# Carregando o dataset
dataset = SingleImageDataset(images_dir, masks_dir, transform=transform)
dataloader = DataLoader(dataset, batch_size=4, shuffle=True)

# Definindo o modelo DeepLabV3, função de perda e otimizador
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = segmentation.deeplabv3_resnet101(pretrained=False, num_classes=21)  # Ajuste num_classes conforme necessário
model.to(device)
criterion = nn.CrossEntropyLoss()  # DeepLabV3 normalmente usa CrossEntropyLoss
optimizer = optim.Adam(model.parameters(), lr=0.001)
scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True)

def train_model(model, dataloader, criterion, optimizer, device, num_epochs, checkpoint_path='deeplabv3_checkpoint.pth', patience=3):
    model.train()
    best_loss = float('inf')
    no_improvement = 0
    
    for epoch in range(num_epochs):
        epoch_loss = 0.0
        for images, masks in dataloader:
            images = images.to(device)
            masks = masks.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)['out']  # A saída do DeepLabV3 é um dicionário
            loss = criterion(outputs, masks)  # CrossEntropyLoss espera os rótulos como inteiros
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        
        epoch_loss /= len(dataloader)
        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')
        
        # Scheduler step
        scheduler.step(epoch_loss)
        
        # Check for early stopping
        if epoch_loss < best_loss:
            best_loss = epoch_loss
            no_improvement = 0
            torch.save(model.state_dict(), checkpoint_path)  # Salvar melhor modelo
        else:
            no_improvement += 1
            if no_improvement >= patience:
                print("Early stopping triggered")
                break

    return model

# Treinando o modelo com menos épocas inicialmente
initial_epochs = 5  # Ajuste conforme necessário
trained_model = train_model(model, dataloader, criterion, optimizer, device, initial_epochs)

# Salvando o modelo treinado
torch.save(trained_model.state_dict(), 'best_deeplabv3_model.pth')
